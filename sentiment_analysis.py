# -*- coding: utf-8 -*-
"""Sentiment Analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r9DdUMWkaUukYJ4JpoM8TgCsnYZKySba
"""

X_train = ["This was really awesome an awesome movie",
           "Great movie! Ilikes it a lot",
           "Happy Ending! Awesome Acting by hero",
           "loved it!",
           "Bad not upto the mark",
           "Could have been better",
           "really Dissapointed by the movie"]
# X_test = "it was really awesome and really disspntd"

y_train = ["positive","positive","positive","positive","negative","negative","neutral"] # 1- Positive class, 0- negative class

X_train # Reviews

"""# Cleaning of the data"""

# Tokenize
# "I am a python dev" -> ["I", "am", "a", "python", "dev"]

from nltk.tokenize import RegexpTokenizer
# NLTK -> Tokenize -> RegexpTokenizer

# Stemming
# "Playing" -> "Play"
# "Working" -> "Work"

from nltk.stem.porter import PorterStemmer
# NLTK -> Stem -> Porter -> PorterStemmer

from nltk.corpus import stopwords
# NLTK -> Corpus -> stopwords

import re
# Downloading the stopwords
import nltk
nltk.download('stopwords')

tokenizer = RegexpTokenizer(r"\w+")
en_stopwords = set(stopwords.words('english'))
ps = PorterStemmer()

def getCleanedText(text):
  text = text.lower()

  # tokenizing
  tokens = tokenizer.tokenize(text)
  new_tokens = [token for token in tokens if token not in en_stopwords]
  stemmed_tokens = [ps.stem(tokens) for tokens in new_tokens]
  clean_text = " ".join(stemmed_tokens)
  return clean_text

"""# Input from the user"""

X_test = ["it was bad"]

X_clean = [getCleanedText(i) for i in X_train]
xt_clean = [getCleanedText(i) for i in X_test]

X_clean

# Data before cleaning
'''
X_train = ["This was awesome an awesome movie",
           "Great movie! Ilikes it a lot",
           "Happy Ending! Awesome Acting by hero",
           "loved it!",
           "Bad not upto the mark",
           "Could have been better",
           "Dissapointed by the movie"]
'''

"""# Vectorize"""

from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer(ngram_range = (1,2))
# "I am PyDev" -> "i am", "am Pydev"

cv = CountVectorizer(max_features=1000)
X_vec = cv.fit_transform(X_clean).toarray()

X_vec

feature_names = cv.get_feature_names_out()

print(cv.get_feature_names_out())

Xt_vect = cv.transform(xt_clean).toarray()

Xt_vect

"""# Multinomial Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

mn = MultinomialNB()

mn.fit(X_vec, y_train)

y_pred = mn.predict(X_vec)

y_pred

user_input = input("Enter a sentence for sentiment analysis: ")
user_input_cleaned =  getCleanedText(user_input)
user_input_tfidf = cv.transform([user_input_cleaned])

sentiment_probs = mn.predict_proba(user_input_tfidf)[0]

if sentiment_probs[0] > sentiment_probs[1] and sentiment_probs[0] > sentiment_probs[2]:
    predicted_sentiment = "negative"
elif sentiment_probs[1] > sentiment_probs[0] and sentiment_probs[1] > sentiment_probs[2]:
    predicted_sentiment = "positive"
else:
    predicted_sentiment = "neutral"
predicted_sentiment = mn.predict(user_input_tfidf)[0]

print(f"Predicted Sentiment: {predicted_sentiment}")

accuracy_train = accuracy_score(y_train, y_pred)
print(f"Accuracy on Training Set: {accuracy_train * 100:.2f}%")